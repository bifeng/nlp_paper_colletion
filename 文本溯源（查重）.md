Text Sourcing Technology

Copy Detection

Text Plagiarism 

### Challenge



### Competition

+ **第一届文本溯源技术评测**

  https://biendata.com/competition/smpetst2018/data/

  <http://www.cips-smp.org/data/>

  [1st](<https://blog.csdn.net/huhehaotechangsha/article/details/80645962#_48>) [5th](<https://github.com/kuhung/SMP-ETST-2018>) 

  >#### 任务描述
  >
  >本次文本溯源技术评测的任务是句子级的检测，即给定一批待查句子和一个源数据集，判断待查句子是否改编自源数据集中的句子，如果是则找出相应的源句子。句子改编的范畴包括但不限于：微修改、增加、部分删简、对文字表述进行概括、改变原有的排列顺序、关键词替换等。 
  >
  >#### 数据说明
  >
  >新闻类数据集

+ **第二届文本溯源技术评测**

  https://biendata.com/competition/smpetst2019/

  <http://www.cips-smp.org/data/>
  
  > ### 数据集说明
  >
  > 本次评测使用的CTSC-19（Chinese Text Sourcing Corpus）语料是在SogouT-16语料基础上进行标注的。SogouT-16语料的版权归搜狗公司和清华大学所有，使用该语料应得到搜狗公司、清华大学的许可。对抄袭文本的改编包括但不限于：1）文本操作，对文本进行混排、删除、插入词或短语等方式生成新文本；2）语义词汇变换，进行同义词、反义词等替换该词生成新文本；3）句法变换，即通过句法变换的方式进行改写；4）释义修改，即要求志愿者在理解的基础上重新撰写。



### Paper

+ A Survey on Natural Language Text Copy Detection October 2003
+ 科技论文原创性检查系统的研究 韩咏 , 孔蕾蕾 , 齐浩亮 - 全国信息检索与内容安全学术会议 - 2009
+ 软件抄袭检测研究综述 田振洲 , 刘烃 , 郑庆华 - 《信息安全学报》 - 2016 - 被引量:7
+ 汉语文本抄袭识别系统研究《南京农业大学》 - 2008 - 被引量:4



### Tools

+ pylucene

  <http://blog.sina.com.cn/s/blog_6d2cab390100vr5l.html>

  <https://www.php.cn/python-tutorials-372617.html>

+ FreeDiscovery 

  FreeDiscovery is an open source e-Discovery and information retrieval engine.

  <https://github.com/FreeDiscovery/FreeDiscovery>

  <http://freediscovery.io/doc/stable/engine/overview.html>

  

+ 雷同报告检测系统

  <http://ir.hit.edu.cn/~tangguohua/>

  [DOC_en](http://ir.hit.edu.cn/~tangguohua/document/mors/ProjectSummary.pdf)][DOC_zh](http://ir.hit.edu.cn/~tangguohua/document/mors/ProjectSummary_CN.pdf)][[CODE](http://kenai.com/projects/mors-project/sources)[[DEMO](http://202.118.250.16:8181/mors-webapp/)]

  基本思路：


  (1) POI提取正文，中文分词，lucene建立索引;

  (2)新来一篇文章，从中抽取10个特征码（随机选一个标点，标点本身以及标点前5个字标点后5个字合并起来为一个特征码），扔到lucene里面去检索，得分较高的几个结果作为疑似雷同
  (3)对疑似雷同的两篇文档，抽取长度超过10的公共子串，如果公共子串字符数之和占文档字符数的比率超过某一阈值，则系统认为这两篇文档雷同

  (4)最后由人工评判系统给出的结果是否真的是雷同。

  

+ Detecting Software Plagiarism

  MOSS (for a Measure Of Software Similarity) <https://theory.stanford.edu/~aiken/moss/>

  JPLAG 

  https://github.com/jplag/jplag

  SIM

  <https://dickgrune.com/Programs/similarity_tester/>



### blog

+ 基于K-gram的winnowing特征提取剽窃查重检测技术（概念篇）<https://blog.csdn.net/chichoxian/article/details/53115067>

+ 【代码克隆检测】基于K-gram hash 分析特征提取技术（代码篇）

  https://blog.csdn.net/chichoxian/article/details/53128303

+ 文本在线查重（Online Copy Detection）的实现

  <https://blog.csdn.net/weixin_43098787/article/details/82836140>

### Summary

+ 检索

  主题

  召回（topic）

+ 对齐

1. 无监督方法（阈值）

   1）字符

   公共子串（子序列）

   sentence level n-gram

   2）语义

   近邻搜索

   sen2vec - 增量训练

   sentence level vector

   3）graph

   子图匹配

2. 有监督方法：

   借鉴机器翻译中的sentence/word aligment方法，构建平行语料

   

   向量空间模型

   fine-tuning

   文本匹配模型（sentence/doc level）

   阅读理解模型（指针）

   机器翻译模型

 3. 其他问题

    特殊字符清洗

    句子简化（提取关键词）

    翻转简体
    
    

#论文查重算法猜想# - 王利锋

[1/2]基于n-gram的句子级检索查重算法，查询流程为（索引过程类似）：（1）使用POI对word进行正文抽取，断句及中文分词；（2）把单个句子看作一个query，并用n-gram表示（bigram和trigram可行性较大），到论文索引库中检索，每个n-gram对应大量句子； 

[2/2]（3）对检索出的多个句子列表（有序）求交；（4）剩下的句子与query句子求相似度，如直接看相同n-gram数目（ungram、bigram），句子间最长公共子序列，等等，给定阈值决定句子是否存在“重复”；（5）查重句子字数累加（连续句子可增加权重）确定重复比例。

